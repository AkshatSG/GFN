{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNBYi0zxaiTznCq760sOwaL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AkshatSG/GFN/blob/main/GFlowNets_Structure_POC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Librarires\n",
        "\n",
        "#For environment (graph-representation)\n",
        "!pip install rdkit networkx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2zeYw5LDBNc",
        "outputId": "4d81b66a-7255-4043-fcf8-c4a3ed1efee1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rdkit\n",
            "  Downloading rdkit-2024.3.5-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (3.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit) (1.26.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit) (10.4.0)\n",
            "Downloading rdkit-2024.3.5-cp310-cp310-manylinux_2_28_x86_64.whl (33.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.1/33.1 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rdkit\n",
            "Successfully installed rdkit-2024.3.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rFpRntwl8Nxr"
      },
      "outputs": [],
      "source": [
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem\n",
        "import networkx as nx\n",
        "\n",
        "class MoleculeEnvironment:\n",
        "    def __init__(self, max_atoms=10, max_rings=2, min_atoms=2):\n",
        "        self.max_atoms = max_atoms\n",
        "        self.max_rings = max_rings\n",
        "        self.min_atoms = min_atoms\n",
        "        self.available_atoms = ['C', 'N', 'O', 'F', 'Cl']\n",
        "        self.available_bond_types = [\n",
        "            Chem.BondType.SINGLE,\n",
        "            Chem.BondType.DOUBLE,\n",
        "            Chem.BondType.TRIPLE,\n",
        "            Chem.BondType.AROMATIC\n",
        "        ]\n",
        "        self.valences = {'C': 4, 'N': 3, 'O': 2, 'F': 1, 'Cl': 1}\n",
        "        self.proxy = MoleculeProxy()\n",
        "        self.reset()\n",
        "        self.agent = GFlowNetAgent(self)\n",
        "\n",
        "    def reset(self):\n",
        "        self.mol = Chem.RWMol()\n",
        "        self.graph = nx.Graph()\n",
        "        self.add_atom('C')\n",
        "        return self.get_state()\n",
        "\n",
        "    def add_atom(self, atom_symbol):\n",
        "        atom_idx = self.mol.AddAtom(Chem.Atom(atom_symbol))\n",
        "        self.graph.add_node(atom_idx, symbol=atom_symbol)\n",
        "        return atom_idx\n",
        "\n",
        "    def add_bond(self, atom1_idx, atom2_idx, bond_type):\n",
        "        if not self.mol.GetBondBetweenAtoms(atom1_idx, atom2_idx):\n",
        "            self.mol.AddBond(atom1_idx, atom2_idx, bond_type)\n",
        "            self.graph.add_edge(atom1_idx, atom2_idx, bond_type=bond_type)\n",
        "\n",
        "        else:\n",
        "            bond = self.mol.GetBondBetweenAtoms(atom1_idx, atom2_idx)\n",
        "            bond.SetBondType(bond_type)\n",
        "            self.graph[atom1_idx][atom2_idx]['bond_type'] = bond_type\n",
        "\n",
        "    def get_mol(self):\n",
        "        return self.mol.GetMol()\n",
        "\n",
        "    def get_graph(self):\n",
        "        return self.graph\n",
        "\n",
        "    def get_state(self):\n",
        "        return {\n",
        "            'num_atoms': self.mol.GetNumAtoms(),\n",
        "            'num_bonds': self.mol.GetNumBonds(),\n",
        "            'atom_types': [atom.GetSymbol() for atom in self.mol.GetAtoms()],\n",
        "            'bond_types': [bond.GetBondType() for bond in self.mol.GetBonds()]\n",
        "        }\n",
        "\n",
        "    def is_terminal(self):\n",
        "        num_atoms = self.mol.GetNumAtoms()\n",
        "        if num_atoms < self.min_atoms:\n",
        "            return False\n",
        "        if num_atoms > self.max_atoms:\n",
        "            return True\n",
        "        if not self.is_valid_molecule():\n",
        "            return True\n",
        "        for atom in self.mol.GetAtoms():\n",
        "            if atom.GetDegree() == 0:\n",
        "                return False\n",
        "        return True\n",
        "\n",
        "    def is_valid_action(self, action):\n",
        "        action_type = action[0]\n",
        "        if action_type == 'add_atom':\n",
        "            return self.mol.GetNumAtoms() < self.max_atoms\n",
        "        elif action_type == 'add_bond':\n",
        "            atom1, atom2, bond_type = action[1], action[2], action[3]\n",
        "            return (atom1 < self.mol.GetNumAtoms() and\n",
        "                    atom2 < self.mol.GetNumAtoms() and\n",
        "                    not self.mol.GetBondBetweenAtoms(atom1, atom2) and\n",
        "                    self.is_valid_bond(atom1, atom2, bond_type))\n",
        "        elif action_type == 'remove_atom':\n",
        "            return self.mol.GetNumAtoms() > 1 and action[1] < self.mol.GetNumAtoms()\n",
        "        elif action_type == 'remove_bond':\n",
        "            return self.mol.GetBondBetweenAtoms(action[1], action[2]) is not None\n",
        "        return False\n",
        "\n",
        "    def is_valid_bond(self, atom1_idx, atom2_idx, bond_type):\n",
        "        atom1 = self.mol.GetAtomWithIdx(atom1_idx)\n",
        "        atom2 = self.mol.GetAtomWithIdx(atom2_idx)\n",
        "\n",
        "        # Convert bond_type to double\n",
        "        bond_type_double = {\n",
        "          Chem.BondType.SINGLE: 1.0,\n",
        "          Chem.BondType.DOUBLE: 2.0,\n",
        "          Chem.BondType.TRIPLE: 3.0,\n",
        "          Chem.BondType.AROMATIC: 1.5\n",
        "        }.get(bond_type, 0.0)\n",
        "\n",
        "        if (atom1.GetExplicitValence() + bond_type_double > self.valences[atom1.GetSymbol()] or\n",
        "            atom2.GetExplicitValence() + bond_type_double > self.valences[atom2.GetSymbol()]):\n",
        "            return False\n",
        "\n",
        "        if self.would_create_too_many_rings(atom1_idx, atom2_idx):\n",
        "            return False\n",
        "\n",
        "        return True\n",
        "\n",
        "    def would_create_too_many_rings(self, atom1_idx, atom2_idx):\n",
        "        temp_graph = self.graph.copy()\n",
        "        temp_graph.add_edge(atom1_idx, atom2_idx)\n",
        "        return len(list(nx.cycle_basis(temp_graph))) > self.max_rings\n",
        "\n",
        "    def get_possible_actions(self):\n",
        "        actions = []\n",
        "        num_atoms = self.mol.GetNumAtoms()\n",
        "        atom_indices = list(range(num_atoms))\n",
        "\n",
        "        for action in [\n",
        "            ('add_atom', atom_type) for atom_type in self.available_atoms\n",
        "        ] + [\n",
        "            ('add_bond', i, j, bond_type)\n",
        "            for i in atom_indices for j in atom_indices if i < j\n",
        "            for bond_type in self.available_bond_types\n",
        "        ] + [\n",
        "            ('remove_atom', i) for i in atom_indices\n",
        "        ] + [\n",
        "            ('remove_bond', bond.GetBeginAtomIdx(), bond.GetEndAtomIdx())\n",
        "            for bond in self.mol.GetBonds()\n",
        "        ]:\n",
        "            if self.is_valid_action(action):\n",
        "                actions.append(action)\n",
        "\n",
        "        return actions\n",
        "\n",
        "    def get_reward(self):\n",
        "        return self.proxy.calculate_reward(self.mol)\n",
        "\n",
        "    def take_action(self, action):\n",
        "        if not self.is_valid_action(action):\n",
        "            raise ValueError(\"Invalid Action\")\n",
        "        action_type = action[0]\n",
        "        if action_type == 'add_atom':\n",
        "            self.add_atom(action[1])\n",
        "        elif action_type == 'add_bond':\n",
        "            self.add_bond(action[1], action[2], action[3])\n",
        "        elif action_type == 'remove_atom':\n",
        "            self.remove_atom(action[1])\n",
        "        elif action_type == 'remove_bond':\n",
        "            if self.mol.GetBondBetweenAtoms(action[1], action[2]):\n",
        "                self.mol.RemoveBond(action[1], action[2])\n",
        "                self.graph.remove_edge(action[1], action[2])\n",
        "\n",
        "        try:\n",
        "            Chem.SanitizeMol(self.mol)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        state = self.get_state()\n",
        "        reward = self.get_reward()\n",
        "        is_terminal = self.is_terminal()\n",
        "\n",
        "        return state, reward, is_terminal\n",
        "\n",
        "    def is_valid_molecule(self):\n",
        "        try:\n",
        "            Chem.SanitizeMol(self.mol)\n",
        "            return True\n",
        "        except:\n",
        "            return False\n",
        "    def sample_trajectory(self):\n",
        "        self.reset()\n",
        "        trajectory = []\n",
        "        state = self.get_state()\n",
        "\n",
        "        while not self.is_terminal():\n",
        "            possible_actions = self.get_possible_actions()\n",
        "            if not possible_actions:\n",
        "                break\n",
        "            action = self.agent.forward_action(state)\n",
        "            next_state, reward, is_terminal = self.take_action(action)\n",
        "            trajectory.append((state, action, next_state, reward, possible_actions))\n",
        "            state = next_state\n",
        "\n",
        "        return trajectory\n",
        "\n",
        "    def get_mol(self):\n",
        "        return self.mol.GetMol()\n",
        "\n",
        "    def remove_atom(self, atom_idx):\n",
        "      if atom_idx >= self.mol.GetNumAtoms():\n",
        "          return\n",
        "\n",
        "      # Remove all bonds connected to this atom from the graph\n",
        "      bonds_to_remove = list(self.graph.edges(atom_idx))\n",
        "      self.graph.remove_edges_from(bonds_to_remove)\n",
        "\n",
        "      # Remove the atom from the graph\n",
        "      self.graph.remove_node(atom_idx)\n",
        "\n",
        "      # Remove the atom from the molecule\n",
        "      self.mol.RemoveAtom(atom_idx)\n",
        "\n",
        "      # Renumber the atoms in the graph\n",
        "      mapping = {old: new for new, old in enumerate(sorted(self.graph.nodes()))}\n",
        "      self.graph = nx.relabel_nodes(self.graph, mapping)\n",
        "\n",
        "    def remove_bond(self, atom1_idx, atom2_idx):\n",
        "      if self.mol.GetBondBetweenAtoms(atom1_idx, atom2_idx):\n",
        "          self.mol.RemoveBond(atom1_idx, atom2_idx)\n",
        "          self.graph.remove_edge(atom1_idx, atom2_idx)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# env = MoleculeEnvironment(max_atoms=10, min_atoms=2)\n",
        "\n",
        "# # Start with the initial state\n",
        "# state = env.reset()\n",
        "# print(\"Initial state:\", state)\n",
        "\n",
        "# # Take some actions\n",
        "# actions = [\n",
        "#     ('add_atom', 'N'),\n",
        "#     ('add_bond', 0, 1, Chem.BondType.SINGLE),\n",
        "#     ('add_atom', 'O'),\n",
        "#     ('add_bond', 1, 2, Chem.BondType.SINGLE),\n",
        "#     ('add_atom', 'C'),\n",
        "#     ('add_bond', 2, 3, Chem.BondType.SINGLE)\n",
        "# ]\n",
        "\n",
        "# for action in actions:\n",
        "#     state, reward, is_terminal = env.take_action(action)\n",
        "#     print(f\"After action {action}:\")\n",
        "#     print(\"State:\", state)\n",
        "#     print(\"Is terminal:\", is_terminal)\n",
        "#     print(\"Reward:\", reward)\n",
        "\n",
        "# # Check final state\n",
        "# print(\"Final molecule is valid:\", env.is_valid_molecule())\n",
        "# print(\"Final reward:\", env.get_reward())"
      ],
      "metadata": {
        "id": "S5S2gvezNrwM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Proxy\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import Descriptors, Crippen, rdMolDescriptors\n",
        "from rdkit.Chem.Descriptors import ExactMolWt\n",
        "from rdkit.Chem import AllChem\n",
        "from rdkit.Contrib.SA_Score import sascorer\n",
        "\n",
        "class MoleculeProxy:\n",
        "    def __init__(self, target_weight=500, target_logp=2.5, max_hbd=5, max_hba=10):\n",
        "        self.target_weight = target_weight\n",
        "        self.target_logp = target_logp\n",
        "        self.max_hbd = max_hbd\n",
        "        self.max_hba = max_hba\n",
        "\n",
        "    def calculate_reward(self, mol):\n",
        "      if mol is None or mol.GetNumAtoms() == 0:\n",
        "        return -10\n",
        "\n",
        "      mol_copy = Chem.Mol(mol)\n",
        "      try:\n",
        "        Chem.SanitizeMol(mol_copy)\n",
        "        AllChem.Compute2DCoords(mol_copy)\n",
        "      except:\n",
        "        return -10\n",
        "\n",
        "      mol_weight = ExactMolWt(mol)\n",
        "      logp = Crippen.MolLogP(mol)\n",
        "      hbd = rdMolDescriptors.CalcNumHBD(mol)\n",
        "      hba = rdMolDescriptors.CalcNumHBA(mol)\n",
        "      sa_score = self.calculate_sa_score(mol)\n",
        "\n",
        "      weight_reward = 1 - abs(mol_weight - self.target_weight) / self.target_weight\n",
        "      logp_reward = 1 - abs(logp - self.target_logp) / max(abs(self.target_logp), 1)\n",
        "      hbd_reward = 1 if hbd <= self.max_hbd else 0\n",
        "      hba_reward = 1 if hba <= self.max_hba else 0\n",
        "      sa_reward = 1 - sa_score / 10\n",
        "\n",
        "      total_reward = (weight_reward + logp_reward + hbd_reward + hba_reward + sa_reward) / 5\n",
        "      return max(0, total_reward)\n",
        "\n",
        "    def calculate_sa_score(self, mol):\n",
        "      # return AllChem.CalcSyntheticAccessibilityScore(mol)\n",
        "      return sascorer.calculateScore(mol)"
      ],
      "metadata": {
        "id": "OTeIl2Xw9EGe"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Policy Models:\n",
        "\n",
        "  #Forward Policy\n",
        "\n",
        "  #Backward Policy"
      ],
      "metadata": {
        "id": "M4HMi1_S9GP_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#GFlowNet Agent"
      ],
      "metadata": {
        "id": "FdTtro4o9sbi"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class PolicyNetwork(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(PolicyNetwork, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc3 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    # def state_to_tensor(self, state):\n",
        "    #     # Convert the state dictionary to a tensor\n",
        "    #     return torch.tensor([\n",
        "    #         state['num_atoms'],\n",
        "    #         state['num_bonds'],\n",
        "    #         len(state['atom_types']),\n",
        "    #         len(state['bond_types'])\n",
        "    #     ], dtype=torch.float32)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        return self.fc3(x)"
      ],
      "metadata": {
        "id": "ds_PQk35Q4wA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GFlowNetAgent:\n",
        "    def __init__(self, env, hidden_dim=64):\n",
        "        self.env = env\n",
        "        self.input_dim = self.get_state_dim()\n",
        "        self.output_dim = self.get_action_dim()\n",
        "\n",
        "        self.forward_policy = PolicyNetwork(self.input_dim, hidden_dim, self.output_dim)\n",
        "        self.backward_policy = PolicyNetwork(self.input_dim, hidden_dim, self.output_dim)\n",
        "\n",
        "    def get_state_dim(self):\n",
        "        return 4  # num_atoms, num_bonds, num_atom_types, num_bond_types\n",
        "\n",
        "    def get_action_dim(self):\n",
        "        return len(self.env.get_possible_actions())\n",
        "\n",
        "    def state_to_tensor(self, state):\n",
        "        return torch.tensor([\n",
        "            state['num_atoms'],\n",
        "            state['num_bonds'],\n",
        "            len(state['atom_types']),\n",
        "            len(state['bond_types'])\n",
        "        ], dtype=torch.float32)\n",
        "\n",
        "    def forward_action(self, state):\n",
        "        state_tensor = self.state_to_tensor(state)\n",
        "        possible_actions = self.env.get_possible_actions()\n",
        "        with torch.no_grad():\n",
        "            action_probs = F.softmax(self.forward_policy(state_tensor), dim=0)\n",
        "        action_index = torch.multinomial(action_probs, 1).item()\n",
        "        return possible_actions[action_index]\n",
        "\n",
        "    def backward_action(self, state):\n",
        "        state_tensor = self.state_to_tensor(state)\n",
        "        possible_actions = self.env.get_possible_actions()\n",
        "        with torch.no_grad():\n",
        "            action_probs = F.softmax(self.backward_policy(state_tensor), dim=0)\n",
        "        action_index = torch.multinomial(action_probs, 1).item()\n",
        "        return possible_actions[action_index]"
      ],
      "metadata": {
        "id": "Vu4UO0zNSc9Q"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def calculate_trajectory_balance_loss(trajectory, agent):\n",
        "      loss = torch.tensor(0.0, requires_grad=True)\n",
        "      Z = torch.tensor(1.0, requires_grad=True)  # Partition function as a tensor\n",
        "      epsilon = 1e-10  # Small constant to prevent log(0)\n",
        "\n",
        "      for i in range(len(trajectory) - 1):\n",
        "          state, action, next_state, reward, possible_actions = trajectory[i]\n",
        "          next_action = trajectory[i+1][1] if i < len(trajectory) - 2 else None\n",
        "\n",
        "          state_tensor = agent.state_to_tensor(state)\n",
        "          next_state_tensor = agent.state_to_tensor(next_state)\n",
        "\n",
        "          forward_logits = agent.forward_policy(state_tensor)\n",
        "          backward_logits = agent.backward_policy(next_state_tensor)\n",
        "\n",
        "          action_index = possible_actions.index(action)\n",
        "\n",
        "          forward_prob = F.softmax(forward_logits, dim=0)[action_index]\n",
        "          backward_prob = F.softmax(backward_logits, dim=0)[action_index] if next_action else torch.tensor(1.0)\n",
        "\n",
        "          if i == 0:\n",
        "              loss = loss + torch.log(Z) + torch.log(forward_prob)\n",
        "          elif i == len(trajectory) - 2:\n",
        "              # Add epsilon to prevent log(0)\n",
        "              loss = loss + torch.log(torch.tensor(max(reward, epsilon), dtype=torch.float32)) - torch.log(backward_prob)\n",
        "          else:\n",
        "              loss = loss + torch.log(forward_prob) - torch.log(backward_prob)\n",
        "\n",
        "      return -loss  # Negative because we want to maximize this quantity"
      ],
      "metadata": {
        "id": "4bzebSPqV_ps"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "def train_gflownet(env, num_episodes=1000, learning_rate=1e-4, clip_value=1.0):\n",
        "    agent = env.agent\n",
        "    optimizer = optim.Adam(list(agent.forward_policy.parameters()) +\n",
        "                           list(agent.backward_policy.parameters()),\n",
        "                           lr=learning_rate)\n",
        "\n",
        "    for episode in range(num_episodes):\n",
        "        trajectory = env.sample_trajectory()\n",
        "        if not trajectory:\n",
        "            continue\n",
        "        loss = calculate_trajectory_balance_loss(trajectory, agent)\n",
        "\n",
        "        if torch.isnan(loss) or torch.isinf(loss):\n",
        "            print(f\"Warning: Invalid loss value at episode {episode}. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        # Add gradient clipping\n",
        "        nn.utils.clip_grad_norm_(agent.forward_policy.parameters(), clip_value)\n",
        "        nn.utils.clip_grad_norm_(agent.backward_policy.parameters(), clip_value)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        if episode % 100 == 0:\n",
        "            print(f\"Episode {episode}, Loss: {loss.item()}\")\n",
        "\n",
        "        if episode % 1000 == 0:\n",
        "            evaluate_model(env)"
      ],
      "metadata": {
        "id": "mOdmi8z_WtsQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from rdkit import Chem\n",
        "from rdkit.Chem import Descriptors\n",
        "\n",
        "def evaluate_model(env, num_samples=100):\n",
        "    valid_molecules = 0\n",
        "    total_reward = 0\n",
        "    unique_smiles = set()\n",
        "\n",
        "    for _ in range(num_samples):\n",
        "        trajectory = env.sample_trajectory()\n",
        "        final_state = trajectory[-1][2]  # Get the final state\n",
        "        mol = env.get_mol()\n",
        "\n",
        "        if env.is_valid_molecule():\n",
        "            valid_molecules += 1\n",
        "            total_reward += env.get_reward()\n",
        "            smiles = Chem.MolToSmiles(mol)\n",
        "            unique_smiles.add(smiles)\n",
        "\n",
        "    validity_rate = valid_molecules / num_samples\n",
        "    avg_reward = total_reward / valid_molecules if valid_molecules > 0 else 0\n",
        "    uniqueness_rate = len(unique_smiles) / valid_molecules if valid_molecules > 0 else 0\n",
        "\n",
        "    print(f\"Validity rate: {validity_rate:.2f}\")\n",
        "    print(f\"Average reward: {avg_reward:.2f}\")\n",
        "    print(f\"Uniqueness rate: {uniqueness_rate:.2f}\")\n",
        "\n",
        "    # Print some example molecules\n",
        "    print(\"Example generated molecules:\")\n",
        "    for smiles in list(unique_smiles)[:5]:\n",
        "        print(smiles)"
      ],
      "metadata": {
        "id": "mqLr55BYWveG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = MoleculeEnvironment(max_atoms=10, min_atoms=2)\n",
        "import warnings\n",
        "from rdkit import RDLogger\n",
        "RDLogger.DisableLog('rdApp.*')\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "train_gflownet(env)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RR4Gc7pqW5S6",
        "outputId": "64b42581-e6be-4742-e776-8d689cb95062"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 0, Loss: -2.872411012649536\n",
            "Validity rate: 0.33\n",
            "Average reward: 0.68\n",
            "Uniqueness rate: 1.00\n",
            "Example generated molecules:\n",
            "C=N.NOC(Cl)=C1C=C=N1\n",
            "CN(Cl)C(=O)C(Cl)=C(Cl)Cl\n",
            "FCC(Cl)(Cl)Cl.FCl.FF\n",
            "N#CN(CN(F)Cl)OOCl\n",
            "N=C(N)C=O.O=NC(=O)F\n",
            "Episode 100, Loss: -32.127540588378906\n",
            "Episode 200, Loss: -79.93714141845703\n",
            "Episode 300, Loss: -234.4235076904297\n",
            "Episode 400, Loss: -402.9586486816406\n",
            "Episode 500, Loss: -585.8623046875\n",
            "Episode 600, Loss: -845.3506469726562\n",
            "Warning: Invalid loss value at episode 624. Skipping.\n",
            "Warning: Invalid loss value at episode 625. Skipping.\n",
            "Warning: Invalid loss value at episode 626. Skipping.\n",
            "Warning: Invalid loss value at episode 627. Skipping.\n",
            "Warning: Invalid loss value at episode 628. Skipping.\n",
            "Warning: Invalid loss value at episode 629. Skipping.\n",
            "Warning: Invalid loss value at episode 630. Skipping.\n",
            "Warning: Invalid loss value at episode 631. Skipping.\n",
            "Warning: Invalid loss value at episode 632. Skipping.\n",
            "Warning: Invalid loss value at episode 633. Skipping.\n",
            "Warning: Invalid loss value at episode 634. Skipping.\n",
            "Warning: Invalid loss value at episode 635. Skipping.\n",
            "Warning: Invalid loss value at episode 636. Skipping.\n",
            "Warning: Invalid loss value at episode 637. Skipping.\n",
            "Warning: Invalid loss value at episode 638. Skipping.\n",
            "Warning: Invalid loss value at episode 639. Skipping.\n",
            "Warning: Invalid loss value at episode 640. Skipping.\n",
            "Warning: Invalid loss value at episode 641. Skipping.\n",
            "Warning: Invalid loss value at episode 642. Skipping.\n",
            "Warning: Invalid loss value at episode 643. Skipping.\n",
            "Warning: Invalid loss value at episode 644. Skipping.\n",
            "Warning: Invalid loss value at episode 645. Skipping.\n",
            "Warning: Invalid loss value at episode 646. Skipping.\n",
            "Warning: Invalid loss value at episode 647. Skipping.\n",
            "Warning: Invalid loss value at episode 648. Skipping.\n",
            "Warning: Invalid loss value at episode 649. Skipping.\n",
            "Warning: Invalid loss value at episode 650. Skipping.\n",
            "Warning: Invalid loss value at episode 651. Skipping.\n",
            "Warning: Invalid loss value at episode 652. Skipping.\n",
            "Warning: Invalid loss value at episode 653. Skipping.\n",
            "Warning: Invalid loss value at episode 654. Skipping.\n",
            "Warning: Invalid loss value at episode 655. Skipping.\n",
            "Warning: Invalid loss value at episode 656. Skipping.\n",
            "Warning: Invalid loss value at episode 657. Skipping.\n",
            "Warning: Invalid loss value at episode 658. Skipping.\n",
            "Warning: Invalid loss value at episode 659. Skipping.\n",
            "Warning: Invalid loss value at episode 660. Skipping.\n",
            "Warning: Invalid loss value at episode 661. Skipping.\n",
            "Warning: Invalid loss value at episode 662. Skipping.\n",
            "Warning: Invalid loss value at episode 663. Skipping.\n",
            "Warning: Invalid loss value at episode 664. Skipping.\n",
            "Warning: Invalid loss value at episode 665. Skipping.\n",
            "Warning: Invalid loss value at episode 666. Skipping.\n",
            "Warning: Invalid loss value at episode 667. Skipping.\n",
            "Warning: Invalid loss value at episode 668. Skipping.\n",
            "Warning: Invalid loss value at episode 669. Skipping.\n",
            "Warning: Invalid loss value at episode 670. Skipping.\n",
            "Warning: Invalid loss value at episode 671. Skipping.\n",
            "Warning: Invalid loss value at episode 672. Skipping.\n",
            "Warning: Invalid loss value at episode 673. Skipping.\n",
            "Warning: Invalid loss value at episode 674. Skipping.\n",
            "Warning: Invalid loss value at episode 675. Skipping.\n",
            "Warning: Invalid loss value at episode 676. Skipping.\n",
            "Warning: Invalid loss value at episode 677. Skipping.\n",
            "Warning: Invalid loss value at episode 678. Skipping.\n",
            "Warning: Invalid loss value at episode 679. Skipping.\n",
            "Warning: Invalid loss value at episode 680. Skipping.\n",
            "Warning: Invalid loss value at episode 681. Skipping.\n",
            "Warning: Invalid loss value at episode 682. Skipping.\n",
            "Warning: Invalid loss value at episode 683. Skipping.\n",
            "Warning: Invalid loss value at episode 684. Skipping.\n",
            "Warning: Invalid loss value at episode 685. Skipping.\n",
            "Warning: Invalid loss value at episode 686. Skipping.\n",
            "Warning: Invalid loss value at episode 687. Skipping.\n",
            "Warning: Invalid loss value at episode 688. Skipping.\n",
            "Warning: Invalid loss value at episode 689. Skipping.\n",
            "Warning: Invalid loss value at episode 690. Skipping.\n",
            "Warning: Invalid loss value at episode 691. Skipping.\n",
            "Warning: Invalid loss value at episode 692. Skipping.\n",
            "Warning: Invalid loss value at episode 693. Skipping.\n",
            "Warning: Invalid loss value at episode 694. Skipping.\n",
            "Warning: Invalid loss value at episode 695. Skipping.\n",
            "Warning: Invalid loss value at episode 696. Skipping.\n",
            "Warning: Invalid loss value at episode 697. Skipping.\n",
            "Warning: Invalid loss value at episode 698. Skipping.\n",
            "Warning: Invalid loss value at episode 699. Skipping.\n",
            "Warning: Invalid loss value at episode 700. Skipping.\n",
            "Warning: Invalid loss value at episode 701. Skipping.\n",
            "Warning: Invalid loss value at episode 702. Skipping.\n",
            "Warning: Invalid loss value at episode 703. Skipping.\n",
            "Warning: Invalid loss value at episode 704. Skipping.\n",
            "Warning: Invalid loss value at episode 705. Skipping.\n",
            "Warning: Invalid loss value at episode 706. Skipping.\n",
            "Warning: Invalid loss value at episode 707. Skipping.\n",
            "Warning: Invalid loss value at episode 708. Skipping.\n",
            "Warning: Invalid loss value at episode 709. Skipping.\n",
            "Warning: Invalid loss value at episode 710. Skipping.\n",
            "Warning: Invalid loss value at episode 711. Skipping.\n",
            "Warning: Invalid loss value at episode 712. Skipping.\n",
            "Warning: Invalid loss value at episode 713. Skipping.\n",
            "Warning: Invalid loss value at episode 714. Skipping.\n",
            "Warning: Invalid loss value at episode 715. Skipping.\n",
            "Warning: Invalid loss value at episode 716. Skipping.\n",
            "Warning: Invalid loss value at episode 717. Skipping.\n",
            "Warning: Invalid loss value at episode 718. Skipping.\n",
            "Warning: Invalid loss value at episode 719. Skipping.\n",
            "Warning: Invalid loss value at episode 720. Skipping.\n",
            "Warning: Invalid loss value at episode 721. Skipping.\n",
            "Warning: Invalid loss value at episode 722. Skipping.\n",
            "Warning: Invalid loss value at episode 723. Skipping.\n",
            "Warning: Invalid loss value at episode 724. Skipping.\n",
            "Warning: Invalid loss value at episode 725. Skipping.\n",
            "Warning: Invalid loss value at episode 726. Skipping.\n",
            "Warning: Invalid loss value at episode 727. Skipping.\n",
            "Warning: Invalid loss value at episode 728. Skipping.\n",
            "Warning: Invalid loss value at episode 729. Skipping.\n",
            "Warning: Invalid loss value at episode 730. Skipping.\n",
            "Warning: Invalid loss value at episode 731. Skipping.\n",
            "Warning: Invalid loss value at episode 732. Skipping.\n",
            "Warning: Invalid loss value at episode 733. Skipping.\n",
            "Warning: Invalid loss value at episode 734. Skipping.\n",
            "Warning: Invalid loss value at episode 735. Skipping.\n",
            "Warning: Invalid loss value at episode 736. Skipping.\n",
            "Warning: Invalid loss value at episode 737. Skipping.\n",
            "Warning: Invalid loss value at episode 738. Skipping.\n",
            "Warning: Invalid loss value at episode 739. Skipping.\n",
            "Warning: Invalid loss value at episode 740. Skipping.\n",
            "Warning: Invalid loss value at episode 741. Skipping.\n",
            "Warning: Invalid loss value at episode 742. Skipping.\n",
            "Warning: Invalid loss value at episode 743. Skipping.\n",
            "Warning: Invalid loss value at episode 744. Skipping.\n",
            "Warning: Invalid loss value at episode 745. Skipping.\n",
            "Warning: Invalid loss value at episode 746. Skipping.\n",
            "Warning: Invalid loss value at episode 747. Skipping.\n",
            "Warning: Invalid loss value at episode 748. Skipping.\n",
            "Warning: Invalid loss value at episode 749. Skipping.\n",
            "Warning: Invalid loss value at episode 750. Skipping.\n",
            "Warning: Invalid loss value at episode 751. Skipping.\n",
            "Warning: Invalid loss value at episode 752. Skipping.\n",
            "Warning: Invalid loss value at episode 753. Skipping.\n",
            "Warning: Invalid loss value at episode 754. Skipping.\n",
            "Warning: Invalid loss value at episode 755. Skipping.\n",
            "Warning: Invalid loss value at episode 756. Skipping.\n",
            "Warning: Invalid loss value at episode 757. Skipping.\n",
            "Warning: Invalid loss value at episode 758. Skipping.\n",
            "Warning: Invalid loss value at episode 759. Skipping.\n",
            "Warning: Invalid loss value at episode 760. Skipping.\n",
            "Warning: Invalid loss value at episode 761. Skipping.\n",
            "Warning: Invalid loss value at episode 762. Skipping.\n",
            "Warning: Invalid loss value at episode 763. Skipping.\n",
            "Warning: Invalid loss value at episode 764. Skipping.\n",
            "Warning: Invalid loss value at episode 765. Skipping.\n",
            "Warning: Invalid loss value at episode 766. Skipping.\n",
            "Warning: Invalid loss value at episode 767. Skipping.\n",
            "Warning: Invalid loss value at episode 768. Skipping.\n",
            "Warning: Invalid loss value at episode 769. Skipping.\n",
            "Warning: Invalid loss value at episode 770. Skipping.\n",
            "Warning: Invalid loss value at episode 771. Skipping.\n",
            "Warning: Invalid loss value at episode 772. Skipping.\n",
            "Warning: Invalid loss value at episode 773. Skipping.\n",
            "Warning: Invalid loss value at episode 774. Skipping.\n",
            "Warning: Invalid loss value at episode 775. Skipping.\n",
            "Warning: Invalid loss value at episode 776. Skipping.\n",
            "Warning: Invalid loss value at episode 777. Skipping.\n",
            "Warning: Invalid loss value at episode 778. Skipping.\n",
            "Warning: Invalid loss value at episode 779. Skipping.\n",
            "Warning: Invalid loss value at episode 780. Skipping.\n",
            "Warning: Invalid loss value at episode 781. Skipping.\n",
            "Warning: Invalid loss value at episode 782. Skipping.\n",
            "Warning: Invalid loss value at episode 783. Skipping.\n",
            "Warning: Invalid loss value at episode 784. Skipping.\n",
            "Warning: Invalid loss value at episode 785. Skipping.\n",
            "Warning: Invalid loss value at episode 786. Skipping.\n",
            "Warning: Invalid loss value at episode 787. Skipping.\n",
            "Warning: Invalid loss value at episode 788. Skipping.\n",
            "Warning: Invalid loss value at episode 789. Skipping.\n",
            "Warning: Invalid loss value at episode 790. Skipping.\n",
            "Warning: Invalid loss value at episode 791. Skipping.\n",
            "Warning: Invalid loss value at episode 792. Skipping.\n",
            "Warning: Invalid loss value at episode 793. Skipping.\n",
            "Warning: Invalid loss value at episode 794. Skipping.\n",
            "Warning: Invalid loss value at episode 795. Skipping.\n",
            "Warning: Invalid loss value at episode 796. Skipping.\n",
            "Warning: Invalid loss value at episode 797. Skipping.\n",
            "Warning: Invalid loss value at episode 798. Skipping.\n",
            "Warning: Invalid loss value at episode 799. Skipping.\n",
            "Warning: Invalid loss value at episode 800. Skipping.\n",
            "Warning: Invalid loss value at episode 801. Skipping.\n",
            "Warning: Invalid loss value at episode 802. Skipping.\n",
            "Warning: Invalid loss value at episode 803. Skipping.\n",
            "Warning: Invalid loss value at episode 804. Skipping.\n",
            "Warning: Invalid loss value at episode 805. Skipping.\n",
            "Warning: Invalid loss value at episode 806. Skipping.\n",
            "Warning: Invalid loss value at episode 807. Skipping.\n",
            "Warning: Invalid loss value at episode 808. Skipping.\n",
            "Warning: Invalid loss value at episode 809. Skipping.\n",
            "Warning: Invalid loss value at episode 810. Skipping.\n",
            "Warning: Invalid loss value at episode 811. Skipping.\n",
            "Warning: Invalid loss value at episode 812. Skipping.\n",
            "Warning: Invalid loss value at episode 813. Skipping.\n",
            "Warning: Invalid loss value at episode 814. Skipping.\n",
            "Warning: Invalid loss value at episode 815. Skipping.\n",
            "Warning: Invalid loss value at episode 816. Skipping.\n",
            "Warning: Invalid loss value at episode 817. Skipping.\n",
            "Warning: Invalid loss value at episode 818. Skipping.\n",
            "Warning: Invalid loss value at episode 819. Skipping.\n",
            "Warning: Invalid loss value at episode 820. Skipping.\n",
            "Warning: Invalid loss value at episode 821. Skipping.\n",
            "Warning: Invalid loss value at episode 822. Skipping.\n",
            "Warning: Invalid loss value at episode 823. Skipping.\n",
            "Warning: Invalid loss value at episode 824. Skipping.\n",
            "Warning: Invalid loss value at episode 825. Skipping.\n",
            "Warning: Invalid loss value at episode 826. Skipping.\n",
            "Warning: Invalid loss value at episode 827. Skipping.\n",
            "Warning: Invalid loss value at episode 828. Skipping.\n",
            "Warning: Invalid loss value at episode 829. Skipping.\n",
            "Warning: Invalid loss value at episode 830. Skipping.\n",
            "Warning: Invalid loss value at episode 831. Skipping.\n",
            "Warning: Invalid loss value at episode 832. Skipping.\n",
            "Warning: Invalid loss value at episode 833. Skipping.\n",
            "Warning: Invalid loss value at episode 834. Skipping.\n",
            "Warning: Invalid loss value at episode 835. Skipping.\n",
            "Warning: Invalid loss value at episode 836. Skipping.\n",
            "Warning: Invalid loss value at episode 837. Skipping.\n",
            "Warning: Invalid loss value at episode 838. Skipping.\n",
            "Warning: Invalid loss value at episode 839. Skipping.\n",
            "Warning: Invalid loss value at episode 840. Skipping.\n",
            "Warning: Invalid loss value at episode 841. Skipping.\n",
            "Warning: Invalid loss value at episode 842. Skipping.\n",
            "Warning: Invalid loss value at episode 843. Skipping.\n",
            "Warning: Invalid loss value at episode 844. Skipping.\n",
            "Warning: Invalid loss value at episode 845. Skipping.\n",
            "Warning: Invalid loss value at episode 846. Skipping.\n",
            "Warning: Invalid loss value at episode 847. Skipping.\n",
            "Warning: Invalid loss value at episode 848. Skipping.\n",
            "Warning: Invalid loss value at episode 849. Skipping.\n",
            "Warning: Invalid loss value at episode 850. Skipping.\n",
            "Warning: Invalid loss value at episode 851. Skipping.\n",
            "Warning: Invalid loss value at episode 852. Skipping.\n",
            "Warning: Invalid loss value at episode 853. Skipping.\n",
            "Warning: Invalid loss value at episode 854. Skipping.\n",
            "Warning: Invalid loss value at episode 855. Skipping.\n",
            "Warning: Invalid loss value at episode 856. Skipping.\n",
            "Warning: Invalid loss value at episode 857. Skipping.\n",
            "Warning: Invalid loss value at episode 858. Skipping.\n",
            "Warning: Invalid loss value at episode 859. Skipping.\n",
            "Warning: Invalid loss value at episode 860. Skipping.\n",
            "Warning: Invalid loss value at episode 861. Skipping.\n",
            "Warning: Invalid loss value at episode 862. Skipping.\n",
            "Warning: Invalid loss value at episode 863. Skipping.\n",
            "Warning: Invalid loss value at episode 864. Skipping.\n",
            "Warning: Invalid loss value at episode 865. Skipping.\n",
            "Warning: Invalid loss value at episode 866. Skipping.\n",
            "Warning: Invalid loss value at episode 867. Skipping.\n",
            "Warning: Invalid loss value at episode 868. Skipping.\n",
            "Warning: Invalid loss value at episode 869. Skipping.\n",
            "Warning: Invalid loss value at episode 870. Skipping.\n",
            "Warning: Invalid loss value at episode 871. Skipping.\n",
            "Warning: Invalid loss value at episode 872. Skipping.\n",
            "Warning: Invalid loss value at episode 873. Skipping.\n",
            "Warning: Invalid loss value at episode 874. Skipping.\n",
            "Warning: Invalid loss value at episode 875. Skipping.\n",
            "Warning: Invalid loss value at episode 876. Skipping.\n",
            "Warning: Invalid loss value at episode 877. Skipping.\n",
            "Warning: Invalid loss value at episode 878. Skipping.\n",
            "Warning: Invalid loss value at episode 879. Skipping.\n",
            "Warning: Invalid loss value at episode 880. Skipping.\n",
            "Warning: Invalid loss value at episode 881. Skipping.\n",
            "Warning: Invalid loss value at episode 882. Skipping.\n",
            "Warning: Invalid loss value at episode 883. Skipping.\n",
            "Warning: Invalid loss value at episode 884. Skipping.\n",
            "Warning: Invalid loss value at episode 885. Skipping.\n",
            "Warning: Invalid loss value at episode 886. Skipping.\n",
            "Warning: Invalid loss value at episode 887. Skipping.\n",
            "Warning: Invalid loss value at episode 888. Skipping.\n",
            "Warning: Invalid loss value at episode 889. Skipping.\n",
            "Warning: Invalid loss value at episode 890. Skipping.\n",
            "Warning: Invalid loss value at episode 891. Skipping.\n",
            "Warning: Invalid loss value at episode 892. Skipping.\n",
            "Warning: Invalid loss value at episode 893. Skipping.\n",
            "Warning: Invalid loss value at episode 894. Skipping.\n",
            "Warning: Invalid loss value at episode 895. Skipping.\n",
            "Warning: Invalid loss value at episode 896. Skipping.\n",
            "Warning: Invalid loss value at episode 897. Skipping.\n",
            "Warning: Invalid loss value at episode 898. Skipping.\n",
            "Warning: Invalid loss value at episode 899. Skipping.\n",
            "Warning: Invalid loss value at episode 900. Skipping.\n",
            "Warning: Invalid loss value at episode 901. Skipping.\n",
            "Warning: Invalid loss value at episode 902. Skipping.\n",
            "Warning: Invalid loss value at episode 903. Skipping.\n",
            "Warning: Invalid loss value at episode 904. Skipping.\n",
            "Warning: Invalid loss value at episode 905. Skipping.\n",
            "Warning: Invalid loss value at episode 906. Skipping.\n",
            "Warning: Invalid loss value at episode 907. Skipping.\n",
            "Warning: Invalid loss value at episode 908. Skipping.\n",
            "Warning: Invalid loss value at episode 909. Skipping.\n",
            "Warning: Invalid loss value at episode 910. Skipping.\n",
            "Warning: Invalid loss value at episode 911. Skipping.\n",
            "Warning: Invalid loss value at episode 912. Skipping.\n",
            "Warning: Invalid loss value at episode 913. Skipping.\n",
            "Warning: Invalid loss value at episode 914. Skipping.\n",
            "Warning: Invalid loss value at episode 915. Skipping.\n",
            "Warning: Invalid loss value at episode 916. Skipping.\n",
            "Warning: Invalid loss value at episode 917. Skipping.\n",
            "Warning: Invalid loss value at episode 918. Skipping.\n",
            "Warning: Invalid loss value at episode 919. Skipping.\n",
            "Warning: Invalid loss value at episode 920. Skipping.\n",
            "Warning: Invalid loss value at episode 921. Skipping.\n",
            "Warning: Invalid loss value at episode 922. Skipping.\n",
            "Warning: Invalid loss value at episode 923. Skipping.\n",
            "Warning: Invalid loss value at episode 924. Skipping.\n",
            "Warning: Invalid loss value at episode 925. Skipping.\n",
            "Warning: Invalid loss value at episode 926. Skipping.\n",
            "Warning: Invalid loss value at episode 927. Skipping.\n",
            "Warning: Invalid loss value at episode 928. Skipping.\n",
            "Warning: Invalid loss value at episode 929. Skipping.\n",
            "Warning: Invalid loss value at episode 930. Skipping.\n",
            "Warning: Invalid loss value at episode 931. Skipping.\n",
            "Warning: Invalid loss value at episode 932. Skipping.\n",
            "Warning: Invalid loss value at episode 933. Skipping.\n",
            "Warning: Invalid loss value at episode 934. Skipping.\n",
            "Warning: Invalid loss value at episode 935. Skipping.\n",
            "Warning: Invalid loss value at episode 936. Skipping.\n",
            "Warning: Invalid loss value at episode 937. Skipping.\n",
            "Warning: Invalid loss value at episode 938. Skipping.\n",
            "Warning: Invalid loss value at episode 939. Skipping.\n",
            "Warning: Invalid loss value at episode 940. Skipping.\n",
            "Warning: Invalid loss value at episode 941. Skipping.\n",
            "Warning: Invalid loss value at episode 942. Skipping.\n",
            "Warning: Invalid loss value at episode 943. Skipping.\n",
            "Warning: Invalid loss value at episode 944. Skipping.\n",
            "Warning: Invalid loss value at episode 945. Skipping.\n",
            "Warning: Invalid loss value at episode 946. Skipping.\n",
            "Warning: Invalid loss value at episode 947. Skipping.\n",
            "Warning: Invalid loss value at episode 948. Skipping.\n",
            "Warning: Invalid loss value at episode 949. Skipping.\n",
            "Warning: Invalid loss value at episode 950. Skipping.\n",
            "Warning: Invalid loss value at episode 951. Skipping.\n",
            "Warning: Invalid loss value at episode 952. Skipping.\n",
            "Warning: Invalid loss value at episode 953. Skipping.\n",
            "Warning: Invalid loss value at episode 954. Skipping.\n",
            "Warning: Invalid loss value at episode 955. Skipping.\n",
            "Warning: Invalid loss value at episode 956. Skipping.\n",
            "Warning: Invalid loss value at episode 957. Skipping.\n",
            "Warning: Invalid loss value at episode 958. Skipping.\n",
            "Warning: Invalid loss value at episode 959. Skipping.\n",
            "Warning: Invalid loss value at episode 960. Skipping.\n",
            "Warning: Invalid loss value at episode 961. Skipping.\n",
            "Warning: Invalid loss value at episode 962. Skipping.\n",
            "Warning: Invalid loss value at episode 963. Skipping.\n",
            "Warning: Invalid loss value at episode 964. Skipping.\n",
            "Warning: Invalid loss value at episode 965. Skipping.\n",
            "Warning: Invalid loss value at episode 966. Skipping.\n",
            "Warning: Invalid loss value at episode 967. Skipping.\n",
            "Warning: Invalid loss value at episode 968. Skipping.\n",
            "Warning: Invalid loss value at episode 969. Skipping.\n",
            "Warning: Invalid loss value at episode 970. Skipping.\n",
            "Warning: Invalid loss value at episode 971. Skipping.\n",
            "Warning: Invalid loss value at episode 972. Skipping.\n",
            "Warning: Invalid loss value at episode 973. Skipping.\n",
            "Warning: Invalid loss value at episode 974. Skipping.\n",
            "Warning: Invalid loss value at episode 975. Skipping.\n",
            "Warning: Invalid loss value at episode 976. Skipping.\n",
            "Warning: Invalid loss value at episode 977. Skipping.\n",
            "Warning: Invalid loss value at episode 978. Skipping.\n",
            "Warning: Invalid loss value at episode 979. Skipping.\n",
            "Warning: Invalid loss value at episode 980. Skipping.\n",
            "Warning: Invalid loss value at episode 981. Skipping.\n",
            "Warning: Invalid loss value at episode 982. Skipping.\n",
            "Warning: Invalid loss value at episode 983. Skipping.\n",
            "Warning: Invalid loss value at episode 984. Skipping.\n",
            "Warning: Invalid loss value at episode 985. Skipping.\n",
            "Warning: Invalid loss value at episode 986. Skipping.\n",
            "Warning: Invalid loss value at episode 987. Skipping.\n",
            "Warning: Invalid loss value at episode 988. Skipping.\n",
            "Warning: Invalid loss value at episode 989. Skipping.\n",
            "Warning: Invalid loss value at episode 990. Skipping.\n",
            "Warning: Invalid loss value at episode 991. Skipping.\n",
            "Warning: Invalid loss value at episode 992. Skipping.\n",
            "Warning: Invalid loss value at episode 993. Skipping.\n",
            "Warning: Invalid loss value at episode 994. Skipping.\n",
            "Warning: Invalid loss value at episode 995. Skipping.\n",
            "Warning: Invalid loss value at episode 996. Skipping.\n",
            "Warning: Invalid loss value at episode 997. Skipping.\n",
            "Warning: Invalid loss value at episode 998. Skipping.\n",
            "Warning: Invalid loss value at episode 999. Skipping.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2gYr-V8rh927"
      },
      "execution_count": 13,
      "outputs": []
    }
  ]
}